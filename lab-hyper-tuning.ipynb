{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "Finally step in order to maximize the performance on your Spaceship Titanic model.\n",
    "\n",
    "The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been training and evaluating models with default values for hyperparameters.\n",
    "\n",
    "Today we will perform the same feature engineering as before, and then compare the best working models you got so far, but now fine tuning it's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=547a3a4a-1157-487c-9f2c-a1f08e4f57b9 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('547a3a4a-1157-487c-9f2c-a1f08e4f57b9').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "spaceship.head()\n",
    "\n",
    "# Handle missing data\n",
    "spaceship.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Preprocessing\n",
    "# Select numeric and categorical columns\n",
    "numeric_features = spaceship.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = spaceship.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's use the best model we got so far in order to see how it can improve when we fine tune it's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X luego de la transformación: (6954, 19238)\n",
      "\n",
      "=== Entrenando Bagging... ===\n",
      "Bagging entrenado. Realizando predicciones...\n",
      "Bagging Accuracy: 0.7740\n",
      "\n",
      "=== Entrenando Pasting... ===\n",
      "Pasting entrenado. Realizando predicciones...\n",
      "Pasting Accuracy: 0.7775\n",
      "\n",
      "=== Entrenando Random Forest... ===\n",
      "Random Forest entrenado. Realizando predicciones...\n",
      "Random Forest Accuracy: 0.7746\n",
      "\n",
      "=== Entrenando Gradient Boosting... ===\n",
      "Gradient Boosting entrenado. Realizando predicciones...\n",
      "Gradient Boosting Accuracy: 0.7775\n",
      "\n",
      "=== Entrenando Adaptive Boosting... ===\n",
      "Adaptive Boosting entrenado. Realizando predicciones...\n",
      "Adaptive Boosting Accuracy: 0.7706\n",
      "\n",
      "El mejor modelo es Pasting con una exactitud de 0.7775\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 1. Importar librerías\n",
    "# =========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Quita estas dos líneas si tu scikit-learn es < 1.2\n",
    "# from sklearn import set_config\n",
    "# set_config(transform_output=\"pandas\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. Cargar el dataset\n",
    "# =========================================================\n",
    "url = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\"\n",
    "spaceship = pd.read_csv(url)\n",
    "\n",
    "# =========================================================\n",
    "# 3. Manejo de datos faltantes\n",
    "# =========================================================\n",
    "# Rellenar valores faltantes con 'forward fill'\n",
    "spaceship.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# =========================================================\n",
    "# 4. Definir características numéricas y categóricas\n",
    "# =========================================================\n",
    "numeric_features = spaceship.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = spaceship.select_dtypes(include=['object']).columns\n",
    "\n",
    "# =========================================================\n",
    "# 5. ColumnTransformer para preprocesamiento\n",
    "# =========================================================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 6. Definir X e y\n",
    "# =========================================================\n",
    "X = spaceship.drop(columns=['Transported'])  \n",
    "y = spaceship['Transported'].astype(int)\n",
    "\n",
    "# =========================================================\n",
    "# 7. Dividir en train y test\n",
    "# =========================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 8. (Opcional) Probar con subset para debugging rápido\n",
    "# =========================================================\n",
    "# X_train = X_train.head(2000)\n",
    "# y_train = y_train.head(2000)\n",
    "\n",
    "# =========================================================\n",
    "# 9. (Opcional) Revisar cuántas columnas produce la transformación\n",
    "# =========================================================\n",
    "X_preprocessed_sample = preprocessor.fit_transform(X_train)\n",
    "print(\"Shape de X luego de la transformación:\", X_preprocessed_sample.shape)\n",
    "\n",
    "# =========================================================\n",
    "# 10. Definir modelos con parámetros optimizados\n",
    "# =========================================================\n",
    "\n",
    "bagging_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', BaggingClassifier(\n",
    "        base_estimator=RandomForestClassifier(\n",
    "            n_estimators=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        n_estimators=10,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pasting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', BaggingClassifier(\n",
    "        base_estimator=RandomForestClassifier(\n",
    "            n_estimators=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        n_estimators=10,\n",
    "        bootstrap=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "random_forest_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "gradient_boosting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(\n",
    "        n_estimators=50,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "adaptive_boosting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(\n",
    "        n_estimators=50,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================================================\n",
    "# 11. Entrenar y evaluar los modelos\n",
    "# =========================================================\n",
    "models = {\n",
    "    'Bagging': bagging_model,\n",
    "    'Pasting': pasting_model,\n",
    "    'Random Forest': random_forest_model,\n",
    "    'Gradient Boosting': gradient_boosting_model,\n",
    "    'Adaptive Boosting': adaptive_boosting_model\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== Entrenando {model_name}... ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{model_name} entrenado. Realizando predicciones...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[model_name] = accuracy\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# =========================================================\n",
    "# 12. Seleccionar mejor modelo\n",
    "# =========================================================\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"\\nEl mejor modelo es {best_model} con una exactitud de {results[best_model]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "# ============================================\n",
    "# Supongamos que bagging_model es tu pipeline\n",
    "# ============================================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_grid = {\n",
    "    # Hiperparámetros de BaggingClassifier\n",
    "    'classifier__n_estimators': [10, 50, 100],\n",
    "    'classifier__max_samples': [0.5, 0.8, 1.0],\n",
    "    \n",
    "    # Hiperparámetros del RandomForest interno\n",
    "    'classifier__base_estimator__n_estimators': [10, 50],\n",
    "    'classifier__base_estimator__max_depth': [None, 5, 10]\n",
    "}\n",
    "\n",
    "# Crear el objeto de búsqueda\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=bagging_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda en el conjunto de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\\nMejor score en validación cruzada (cv=5):\")\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# Predecir con el mejor modelo encontrado\n",
    "best_bagging = grid_search.best_estimator_\n",
    "y_pred = best_bagging.predict(X_test)\n",
    "\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy en test con el modelo optimizado:\", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid/Random Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we will use Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define hyperparameters to fine tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Buscando mejores hiperparámetros para Pasting... ===\n",
      "\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'classifier__base_estimator__max_depth': None, 'classifier__base_estimator__n_estimators': 50, 'classifier__max_features': 1.0, 'classifier__max_samples': 1.0, 'classifier__n_estimators': 20}\n",
      "\n",
      "Accuracy con el mejor modelo de Pasting: 0.7803\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# 1. Importar librerías\n",
    "# =============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Quita o comenta las siguientes líneas si tu scikit-learn es < 1.2\n",
    "# from sklearn import set_config\n",
    "# set_config(transform_output=\"pandas\")\n",
    "\n",
    "# =============================================\n",
    "# 2. Cargar y preparar el dataset\n",
    "# =============================================\n",
    "url = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\"\n",
    "spaceship = pd.read_csv(url)\n",
    "\n",
    "# Manejo de nulos\n",
    "spaceship.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Definir numéricas y categóricas\n",
    "numeric_features = spaceship.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = spaceship.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = spaceship.drop(columns=['Transported'])  \n",
    "y = spaceship['Transported'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =============================================\n",
    "# 3. Definir el pipeline del mejor modelo (Pasting)\n",
    "# =============================================\n",
    "pasting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', BaggingClassifier(\n",
    "        base_estimator=RandomForestClassifier(\n",
    "            n_estimators=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        n_estimators=10,\n",
    "        bootstrap=False,   # La diferencia de \"pasting\" vs \"bagging\"\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =============================================\n",
    "# 4. Definir rejilla de hiperparámetros\n",
    "#    (Se ajustan tanto parámetros del Bagging\n",
    "#     como del RandomForest base)\n",
    "# =============================================\n",
    "param_grid = {\n",
    "    # Hiperparámetros del BaggingClassifier\n",
    "    'classifier__n_estimators': [5, 10, 20],         # Cuántos \"bags\"\n",
    "    'classifier__max_samples': [0.5, 1.0],          # Tamaño de muestreo\n",
    "    'classifier__max_features': [0.5, 1.0],         # Proporción de features\n",
    "    \n",
    "    # Hiperparámetros del RandomForest base\n",
    "    'classifier__base_estimator__n_estimators': [5, 10, 50],\n",
    "    'classifier__base_estimator__max_depth': [None, 5, 10],\n",
    "}\n",
    "\n",
    "# =============================================\n",
    "# 5. Hacer la búsqueda de hiperparámetros\n",
    "# =============================================\n",
    "grid_search = GridSearchCV(\n",
    "    pasting_model, \n",
    "    param_grid=param_grid, \n",
    "    cv=5,             # 5-Fold Cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1         # Paralelizar\n",
    ")\n",
    "\n",
    "print(\"\\n=== Buscando mejores hiperparámetros para Pasting... ===\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# =============================================\n",
    "# 6. Imprimir mejores hiperparámetros\n",
    "# =============================================\n",
    "print(\"\\nMejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# =============================================\n",
    "# 7. Reentrenar y evaluar con esos parámetros\n",
    "# =============================================\n",
    "best_pasting = grid_search.best_estimator_\n",
    "y_pred = best_pasting.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy con el mejor modelo de Pasting: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate your model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

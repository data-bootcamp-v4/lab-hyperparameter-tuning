{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "Finally step in order to maximize the performance on your Spaceship Titanic model.\n",
    "\n",
    "The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been training and evaluating models with default values for hyperparameters.\n",
    "\n",
    "Today we will perform the same feature engineering as before, and then compare the best working models you got so far, but now fine tuning it's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled numerical features:\n",
      "        Age  RoomService  FoodCourt  ShoppingMall       Spa    VRDeck\n",
      "0  0.702095    -0.337025  -0.284274     -0.287317 -0.273736 -0.266098\n",
      "1 -0.333233    -0.173528  -0.278689     -0.245971  0.209267 -0.227692\n",
      "2  2.013510    -0.272527   1.934922     -0.287317  5.634034 -0.223327\n",
      "3  0.287964    -0.337025   0.511931      0.326250  2.655075 -0.097634\n",
      "4 -0.885407     0.117466  -0.240833     -0.037590  0.223344 -0.264352\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "spaceship.head()\n",
    "\n",
    "# Define the numerical features that need to be scaled (replace these with actual feature names)\n",
    "numerical_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']  # These are the actual numerical features in the dataset\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling to the numerical features\n",
    "spaceship[numerical_features] = scaler.fit_transform(spaceship[numerical_features])\n",
    "\n",
    "# Print the scaled data (optional)\n",
    "print(\"Scaled numerical features:\")\n",
    "print(spaceship[numerical_features].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's use the best model we got so far in order to see how it can improve when we fine tune it's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Hyperparameters:  {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score:  0.7469103020962095\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       861\n",
      "           1       0.79      0.70      0.74       878\n",
      "\n",
      "    accuracy                           0.75      1739\n",
      "   macro avg       0.75      0.75      0.75      1739\n",
      "weighted avg       0.75      0.75      0.75      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the data\n",
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "\n",
    "# Remove irrelevant features (PassengerId and Name might not be useful for prediction)\n",
    "spaceship = spaceship.drop(columns=['PassengerId', 'Name'])\n",
    "\n",
    "# Handle categorical variables with One-Hot-Encoding\n",
    "spaceship_encoded = pd.get_dummies(spaceship, columns=['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP'], drop_first=True)\n",
    "\n",
    "# Define the features (X) and the target variable (y)\n",
    "X = spaceship_encoded.drop('Transported', axis=1)  # Assuming 'Transported' is your target variable\n",
    "y = spaceship_encoded['Transported']  # Target variable\n",
    "\n",
    "# Convert the target variable to binary (True/False to 1/0)\n",
    "y = y.astype(int)\n",
    "\n",
    "# Train/Test Split (you can adjust test size if needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model (RandomForest in this case)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid you want to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],        # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30],              # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10]         # Minimum number of samples required to split a node\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters and best model performance\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       861\n",
      "           1       0.79      0.70      0.74       878\n",
      "\n",
      "    accuracy                           0.75      1739\n",
      "   macro avg       0.75      0.75      0.75      1739\n",
      "weighted avg       0.75      0.75      0.75      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Use the best estimator from GridSearch to predict on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid/Random Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we will use Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define hyperparameters to fine tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Hyperparameters:  {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Score:  0.7446097988611268\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       861\n",
      "           1       0.78      0.70      0.74       878\n",
      "\n",
      "    accuracy                           0.75      1739\n",
      "   macro avg       0.75      0.75      0.75      1739\n",
      "weighted avg       0.75      0.75      0.75      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid you want to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],        # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30],              # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10]         # Minimum number of samples required to split a node\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters and best model performance\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters:  {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': True}\n",
      "Best Score:  0.7996844048844318\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78       861\n",
      "           1       0.78      0.80      0.79       878\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.79      0.79      0.79      1739\n",
      "weighted avg       0.79      0.79      0.79      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid you want to search over\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters and best model performance\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best Score: \", random_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Hyperparameters:  {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Score:  0.7461913948352461\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       861\n",
      "           1       0.79      0.69      0.74       878\n",
      "\n",
      "    accuracy                           0.75      1739\n",
      "   macro avg       0.75      0.75      0.75      1739\n",
      "weighted avg       0.75      0.75      0.75      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the data\n",
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "\n",
    "# Remove irrelevant features (PassengerId and Name might not be useful for prediction)\n",
    "spaceship = spaceship.drop(columns=['PassengerId', 'Name'])\n",
    "\n",
    "# Handle categorical variables with One-Hot-Encoding\n",
    "spaceship_encoded = pd.get_dummies(spaceship, columns=['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP'], drop_first=True)\n",
    "\n",
    "# Define the features (X) and the target variable (y)\n",
    "X = spaceship_encoded.drop('Transported', axis=1)  # Assuming 'Transported' is your target variable\n",
    "y = spaceship_encoded['Transported']  # Target variable\n",
    "\n",
    "# Convert the target variable to binary (True/False to 1/0)\n",
    "y = y.astype(int)\n",
    "\n",
    "# Train/Test Split (you can adjust test size if needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model (RandomForest in this case)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid you want to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],        # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30],              # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10]         # Minimum number of samples required to split a node\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters and best model performance\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Best Hyperparameters: \", best_params)\n",
    "print(\"Best Score: \", best_score)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76       861\n",
      "           1       0.79      0.69      0.74       878\n",
      "\n",
      "    accuracy                           0.75      1739\n",
      "   macro avg       0.75      0.75      0.75      1739\n",
      "weighted avg       0.75      0.75      0.75      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Use the best estimator from GridSearch to predict on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "Finally step in order to maximize the performance on your Spaceship Titanic model.\n",
    "\n",
    "The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been training and evaluating models with default values for hyperparameters.\n",
    "\n",
    "Today we will perform the same feature engineering as before, and then compare the best working models you got so far, but now fine tuning it's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shape of the data\n",
    "spaceship.shape\n",
    "\n",
    "#Check for data types\n",
    "spaceship.dtypes\n",
    "\n",
    "#Check for missing values\n",
    "spaceship.isnull().sum()\n",
    "\n",
    "#- Removing all rows or all columns containing missing data.\n",
    "#For this exercise, because we have such low amount of null values, we will drop rows containing any missing value.\n",
    "spaceship.dropna()\n",
    "spaceship.dropna(subset=['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], inplace=True)\n",
    "\n",
    "#**Cabin** is too granular - transform it in order to obtain {'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'}\n",
    "# Transform the Cabin column to extract the first letter\n",
    "spaceship['Cabin'] = spaceship['Cabin'].str[0]\n",
    "\n",
    "# Optionally, ensure that only the expected categories are present\n",
    "valid_categories = {'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'}\n",
    "spaceship = spaceship[spaceship['Cabin'].isin(valid_categories)]\n",
    " \n",
    "# - Drop PassengerId and Name\n",
    "spaceship.drop(['PassengerId', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "spaceship.dropna(inplace=True)\n",
    "spaceship['Cabin'] = spaceship['Cabin'].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features available: 6\n",
      "Features selected by SelectKBest: Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# After preprocessing (dummy encoding and missing value handling)\n",
    "num_features = X.shape[1]\n",
    "print(f\"Number of features available: {num_features}\")\n",
    "\n",
    "# Adjust 'k' to a value less than or equal to the available number of features\n",
    "k = min(10, num_features)  # Adjust 'k' accordingly, here set to 10 or lower if fewer features are available\n",
    "\n",
    "# Apply SelectKBest with Chi-Squared Test\n",
    "select_k_best = SelectKBest(score_func=chi2, k=k)\n",
    "X_kbest = select_k_best.fit_transform(X, y)\n",
    "selected_features_kbest = X.columns[select_k_best.get_support()]\n",
    "\n",
    "print(\"Features selected by SelectKBest:\", selected_features_kbest)\n",
    "\n",
    "# Continue with RFE and Feature Importance as before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by SelectKBest: Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object')\n",
      "Features selected by RFE: Index(['Age', 'RoomService', 'FoodCourt', 'Spa', 'VRDeck'], dtype='object')\n",
      "Feature importances from RandomForest:\n",
      "RoomService: 0.2439\n",
      "Spa: 0.2378\n",
      "VRDeck: 0.2093\n",
      "FoodCourt: 0.1771\n",
      "Age: 0.1318\n",
      "Final top features selected based on importance threshold: ['RoomService', 'Spa', 'VRDeck', 'FoodCourt', 'Age']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Accuracy: 0.7783\n",
      "AdaBoost Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.71      0.77       699\n",
      "        True       0.73      0.85      0.79       654\n",
      "\n",
      "    accuracy                           0.78      1353\n",
      "   macro avg       0.78      0.78      0.78      1353\n",
      "weighted avg       0.79      0.78      0.78      1353\n",
      "\n",
      "Shape of the final refined feature set: (6764, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Accuracy: 0.7938\n",
      "AdaBoost Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.73      0.79       699\n",
      "        True       0.75      0.86      0.80       654\n",
      "\n",
      "    accuracy                           0.79      1353\n",
      "   macro avg       0.80      0.80      0.79      1353\n",
      "weighted avg       0.80      0.79      0.79      1353\n",
      "\n",
      "Features selected by SelectKBest: Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object')\n",
      "Features selected by RFE: Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object')\n",
      "Feature importances from RandomForest:\n",
      "Spa: 0.2089\n",
      "RoomService: 0.2001\n",
      "VRDeck: 0.1827\n",
      "FoodCourt: 0.1598\n",
      "ShoppingMall: 0.1345\n",
      "Age: 0.1141\n",
      "Final top features selected based on importance threshold: ['Spa', 'RoomService', 'VRDeck', 'FoodCourt', 'ShoppingMall', 'Age']\n",
      "Shape of the final refined feature set: (6764, 6)\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Assume X and y are your feature set and target variable\n",
    "# For demonstration purposes, we'll simulate loading and preprocessing\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select the features and target variable\n",
    "X = spaceship.drop(columns=['Transported','HomePlanet','CryoSleep','Cabin','Destination','VIP'])\n",
    "y = spaceship['Transported']\n",
    "\n",
    "# Fill in any missing values\n",
    "X.fillna(X.median(), inplace=True)\n",
    "y.fillna(y.mode()[0], inplace=True)\n",
    "\n",
    "# Convert categorical variables to dummies (one-hot encoding)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Step 5: Apply SelectKBest with Chi-Squared Test\n",
    "k = min(10, X.shape[1])  # Ensure 'k' does not exceed the number of features\n",
    "select_k_best = SelectKBest(score_func=chi2, k=k)\n",
    "X_kbest = select_k_best.fit_transform(X, y)\n",
    "selected_features_kbest = X.columns[select_k_best.get_support()]\n",
    "\n",
    "print(\"Features selected by SelectKBest:\", selected_features_kbest)\n",
    "\n",
    "# Step 6: Recursive Feature Elimination (RFE)\n",
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(log_reg, n_features_to_select=5)  # Further refine to top 5 features\n",
    "X_rfe = rfe.fit_transform(X_kbest, y)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "\n",
    "print(\"Features selected by RFE:\", selected_features_rfe)\n",
    "\n",
    "# Step 7: Feature Importance using RandomForest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_rfe, y)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Combine feature names and their importances\n",
    "feature_importance = list(zip(selected_features_rfe, importances))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)  # Sort by importance\n",
    "\n",
    "print(\"Feature importances from RandomForest:\")\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Optional: Select top features based on importance threshold\n",
    "threshold = 0.05  # Example threshold for feature importance\n",
    "top_features_final = [f for f, importance in feature_importance if importance >= threshold]\n",
    "\n",
    "print(\"Final top features selected based on importance threshold:\", top_features_final)\n",
    "\n",
    "# Final refined feature set\n",
    "X_final_refined = X_rfe[:, [i for i, f in enumerate(selected_features_rfe) if f in top_features_final]]\n",
    "\n",
    "# Step 8: Split the final refined data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final_refined, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Step 9: Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 10: Initialize and train the AdaBoost classifier\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1), \n",
    "    n_estimators=100, \n",
    "    learning_rate=0.5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 11: Make predictions on the test set\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "\n",
    "# Step 12: Evaluate the model's performance\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "print(f\"AdaBoost Classifier Accuracy: {accuracy_ada:.4f}\")\n",
    "\n",
    "print(\"AdaBoost Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_ada))\n",
    "\n",
    "# Final refined feature set shape\n",
    "print(\"Shape of the final refined feature set:\", X_final_refined.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Step 6: Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 7: Initialize and train the AdaBoost classifier\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1), \n",
    "    n_estimators=100, \n",
    "    learning_rate=0.5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Evaluate the model's performance\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "print(f\"AdaBoost Classifier Accuracy: {accuracy_ada:.4f}\")\n",
    "\n",
    "print(\"AdaBoost Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_ada))\n",
    "\n",
    "# Step 1: SelectKBest with Chi-Squared Test\n",
    "k = 6  # Start with a relatively large k to retain more features initially\n",
    "select_k_best = SelectKBest(score_func=chi2, k=k)\n",
    "X_kbest = select_k_best.fit_transform(X, y)\n",
    "selected_features_kbest = X.columns[select_k_best.get_support()]\n",
    "\n",
    "print(\"Features selected by SelectKBest:\", selected_features_kbest)\n",
    "\n",
    "# Step 2: Recursive Feature Elimination (RFE)\n",
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(log_reg, n_features_to_select=10)  # Further refine to top 10 features\n",
    "X_rfe = rfe.fit_transform(X_kbest, y)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "\n",
    "print(\"Features selected by RFE:\", selected_features_rfe)\n",
    "\n",
    "# Step 3: Feature Importance using RandomForest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_rfe, y)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Combine feature names and their importances\n",
    "feature_importance = list(zip(selected_features_rfe, importances))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)  # Sort by importance\n",
    "\n",
    "print(\"Feature importances from RandomForest:\")\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Optional: Select top features based on importance threshold\n",
    "threshold = 0.05  # Example threshold for feature importance\n",
    "top_features_final = [f for f, importance in feature_importance if importance >= threshold]\n",
    "\n",
    "print(\"Final top features selected based on importance threshold:\", top_features_final)\n",
    "\n",
    "# Final refined feature set\n",
    "X_final_refined = X_rfe[:, [i for i, f in enumerate(selected_features_rfe) if f in top_features_final]]\n",
    "\n",
    "# You can now use X_final_refined for further modeling\n",
    "print(\"Shape of the final refined feature set:\", X_final_refined.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's use the best model we got so far in order to see how it can improve when we fine tune it's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Accuracy: 0.7937915742793792\n",
      "AdaBoost Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.73      0.79       699\n",
      "        True       0.75      0.86      0.80       654\n",
      "\n",
      "    accuracy                           0.79      1353\n",
      "   macro avg       0.80      0.80      0.79      1353\n",
      "weighted avg       0.80      0.79      0.79      1353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=100,\n",
    "    learning_rate=0.5, random_state=42)\n",
    "\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "\n",
    "print(\"AdaBoost Classifier Accuracy:\", accuracy_score(y_test, y_pred_ada))\n",
    "print(\"AdaBoost Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7937915742793792,\n",
       " '              precision    recall  f1-score   support\\n\\n       False       0.85      0.73      0.79       699\\n        True       0.75      0.86      0.80       654\\n\\n    accuracy                           0.79      1353\\n   macro avg       0.80      0.80      0.79      1353\\nweighted avg       0.80      0.79      0.79      1353\\n')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "classification_report_ada = classification_report(y_test, y_pred_ada)\n",
    "\n",
    "# Display the results\n",
    "accuracy_ada, classification_report_ada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid/Random Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we will use Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define hyperparameters to fine tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "    'base_estimator__max_depth': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "# Define a more refined parameter grid\n",
    "param_grid_refined = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
    "    'base_estimator__max_depth': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Initialize the AdaBoost model with DecisionTreeClassifier as the base estimator\n",
    "ada_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier()),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;base_estimator__max_depth&#x27;: [2, 3, 4],\n",
       "                         &#x27;learning_rate&#x27;: [0.05, 0.1, 0.2, 0.3],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier()),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;base_estimator__max_depth&#x27;: [2, 3, 4],\n",
       "                         &#x27;learning_rate&#x27;: [0.05, 0.1, 0.2, 0.3],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=AdaBoostClassifier(base_estimator=DecisionTreeClassifier()),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'base_estimator__max_depth': [2, 3, 4],\n",
       "                         'learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=ada_clf, param_grid=param_grid_refined, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the Grid Search to the data\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'base_estimator__max_depth': 2, 'learning_rate': 0.1, 'n_estimators': 200},\n",
       " 0.7924291446837867)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_params, best_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
